# Технические спецификации

**Дата создания:** 2026-02-12  
**Последнее обновление:** 2026-02-12

## Технологический стек

### Язык программирования
- **Python 3.9+** - основной язык разработки
  - Простота использования
  - Богатая экосистема библиотек
  - Хорошая поддержка работы с API и Excel

### Основные библиотеки

1. **selenium** - для автоматизации браузера и работы с динамическим контентом
   - Версия: последняя стабильная
   - Назначение: загрузка JavaScript-контента на страницах 2GIS
   - Требует установки WebDriver (ChromeDriver или GeckoDriver)

2. **beautifulsoup4** - для парсинга HTML
   - Версия: последняя стабильная
   - Назначение: извлечение данных из HTML страниц

3. **requests** - для HTTP запросов (опционально, для статических страниц)
   - Версия: последняя стабильная
   - Назначение: выполнение HTTP запросов к публичным страницам

4. **openpyxl** - для работы с Excel файлами
   - Версия: последняя стабильная
   - Назначение: создание и запись Excel файлов (.xlsx)

5. **click** - для создания CLI интерфейса
   - Версия: последняя стабильная
   - Назначение: удобный командный интерфейс

### Дополнительные библиотеки

- **lxml** - быстрый парсер для BeautifulSoup
- **webdriver-manager** - автоматическое управление WebDriver
- **typing** - для типизации (встроена в Python 3.5+)
- **logging** - для логирования (встроена)
- **time** - для задержек между запросами (встроена)
- **re** - для регулярных выражений (встроена)

## Методы разработки

### Структура проекта

```
2gis-lead-gen/
├── project-docs/          # Документация проекта
├── src/                    # Исходный код
│   ├── __init__.py
│   ├── scraper.py         # Веб-скрапер для 2GIS
│   ├── excel_exporter.py  # Экспорт в Excel
│   ├── models.py          # Модели данных
│   └── cli.py             # CLI интерфейс
├── .gitignore
├── requirements.txt       # Зависимости проекта
├── README.md              # Документация пользователя
└── main.py                # Точка входа
```

### Архитектура

1. **scraper.py** - модуль для веб-скрапинга 2GIS
   - Класс `TwoGISScraper`
   - Методы: `search_companies()`, `parse_company_page()`, `get_city_url()`
   - Использует Selenium для динамического контента
   - Использует BeautifulSoup для парсинга HTML

2. **excel_exporter.py** - модуль для экспорта данных
   - Класс `ExcelExporter`
   - Метод: `export_to_excel()`

3. **models.py** - модели данных
   - Класс `Company` - модель компании
   - Dataclass для структурирования данных

4. **cli.py** - CLI интерфейс
   - Команды для поиска и экспорта
   - Валидация входных данных

5. **main.py** - точка входа
   - Инициализация и запуск приложения

## Стандарты кодирования

### Стиль кода
- **PEP 8** - стандарт стиля кода Python
- Максимальная длина строки: 100 символов
- Использование типов (type hints)

### Именование
- Классы: `PascalCase` (например, `TwoGISClient`)
- Функции и переменные: `snake_case` (например, `search_companies`)
- Константы: `UPPER_SNAKE_CASE` (например, `API_BASE_URL`)

### Комментарии
- Docstrings для всех функций и классов
- Комментарии для сложной логики
- Комментарии на русском языке для пользователя

### Обработка ошибок
- Использование исключений с информативными сообщениями
- Логирование ошибок
- Graceful degradation при ошибках API

## Дизайн базы данных

**База данных не используется** - приложение работает как поисковая система без локального хранения данных. Все данные получаются через API по требованию.

## Конфигурация

### Конфигурационные параметры
- Таймаут загрузки страниц: 30 секунд
- Максимальное количество повторных попыток: 3
- Задержка между запросами: 2-3 секунды (для избежания блокировок)
- Headless режим браузера: по умолчанию включен
- User-Agent: случайный для имитации реального браузера

## Безопасность и этика скрапинга

1. **Соблюдение правил:**
   - Использование разумных задержек между запросами
   - Соблюдение robots.txt (если применимо)
   - Уважение к серверу и не перегрузка его запросами

2. **Валидация входных данных:**
   - Проверка всех пользовательских входных данных
   - Санитизация URL и параметров поиска

3. **Обработка ошибок:**
   - Graceful handling блокировок и капч
   - Информативные сообщения об ошибках
   - Логирование для отладки

4. **User-Agent и заголовки:**
   - Использование реалистичных User-Agent
   - Ротация заголовков для избежания детекции

## Тестирование

### Типы тестов
- Unit тесты для отдельных модулей
- Integration тесты для работы с API (с mock данными)
- CLI тесты для проверки интерфейса

### Инструменты тестирования
- **pytest** - фреймворк для тестирования
- **pytest-mock** - для мокирования API запросов

## Развертывание

### Требования
- Python 3.9 или выше
- pip для установки зависимостей

### Установка
1. Создать виртуальное окружение
2. Установить зависимости из `requirements.txt`
3. Установить ChromeDriver или GeckoDriver (webdriver-manager может сделать это автоматически)
4. Запустить приложение

### Использование
```bash
python main.py search --city "Москва" --category "Кафе" --output results.xlsx
```

**Примечание:** Для работы требуется установленный браузер Chrome или Firefox (для Selenium)
